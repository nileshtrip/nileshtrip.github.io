---
layout: default
---

I'm currently a researcher at Google DeepMind, where I work on language models and more broadly topics related to machine learning and artificial intelligence.

I recently completed my PhD at UC Berkeley in computer science advised by Michael Jordan. Before that I received an M.Phil from the University of Cambridge where I was supervised by Zoubin Ghahramani, and a B.A. in Physics from Harvard University.


## Contact

email:  "firstname"_"lastname"@berkeley.edu

## Selected Publications

_Michelangelo: Long Context Evaluations Beyond Haystacks via Latent Structure Queries_\
Kiran Vodrahalli, Santiago Ontanon, Nilesh Tripuraneni, Kelvin Xu, Sanil Jain, Rakesh Shivanna, Jeffrey Hui, Nishanth Dikkala, Mehran Kazemi, Bahare Fatemi, Rohan Anil, Ethan Dyer, Siamak Shakeri, Roopali Vij, Harsh Mehta, Vinay Ramasesh, Quoc Le, Ed Chi, Yifeng Lu, Orhan Firat, Angeliki Lazaridou, Jean-Baptiste Lespiau, Nithya Attaluri, Kate Olszewska\
_Preprint_ [arxiv](https://arxiv.org/abs/2409.12640)

_Choosing a Proxy Metric from Past Experiments_\
N. Tripuraneni, L. Richardson, A. D'Amour, J. Soriano, S. Yadlowsky\
_KDD 2024_ [arxiv](https://arxiv.org/abs/2309.07893)

_Pretraining Data Mixtures Enable Narrow Model Selection
Capabilities in Transformer Models_\
S. Yadlowsky, L. Doshi, N. Tripuraneni\
_Preprint_ [arxiv](https://arxiv.org/abs/2311.00871)

_Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context_\
Gemini Team, Google.\
_Preprint_ [arxiv](https://arxiv.org/abs/2403.05530)

_Gemini: a family of highly capable multimodal models_\
Gemini Team, Google.\
_Preprint_ [arxiv](https://arxiv.org/abs/2312.11805)

_Optimal Mean Estimation without a Variance_\
Y. Cherapanamjeri, N. Tripuraneni, P. Bartlett, M. I. Jordan\
_Conference on Learning Theory (COLT) 2022_ [COLT](https://proceedings.mlr.press/v178/cherapanamjeri22a.html)  [arxiv](https://arxiv.org/abs/2011.12433)

_Overparameterization Improves Robustness to Covariate Shift in High Dimensions/Covariate Shift in High-Dimensional Random Feature Regression_\
N. Tripuraneni, B. Adlam, J. Pennington\
_Conference on Neural Information Processing Systems (NeurIPS) 2021_ [NeurIPS](https://proceedings.neurips.cc/paper/2021/hash/73fed7fd472e502d8908794430511f4d-Abstract.html) [arxiv](https://arxiv.org/abs/2111.08234)

_On the Theory of Transfer Learning: The Importance of Task Diversity_\
N. Tripuraneni, M. I. Jordan, C. Jin\
_Conference on Neural Information Processing Systems (NeurIPS) 2020_ [NeurIPS](https://proceedings.neurips.cc/paper/2020/hash/59587bffec1c7846f3e34230141556ae-Abstract.html)  [arxiv](https://arxiv.org/abs/2006.11650)

_Stochastic Cubic Regularization for Fast Nonconvex Optimization_\
N. Tripuraneni, M. Stern, C. Jin, J. Regier, M. I. Jordan\
_Conference on Neural Information Processing Systems (NeurIPS) 2018_ [NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2018/file/db1915052d15f7815c8b88e879465a1e-Paper.pdf)  [arxiv](https://arxiv.org/abs/1711.02838)

_Magnetic Hamiltonian Monte Carlo_\
N. Tripuraneni, M. Rowland, Z. Ghahramani, R. Turner\
_International Conference on Machine Learning (ICML) 2017_ [ICML](https://proceedings.mlr.press/v70/tripuraneni17a.html) [arxiv](https://arxiv.org/abs/1607.02738)
